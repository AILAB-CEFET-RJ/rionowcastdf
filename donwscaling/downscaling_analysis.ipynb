{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALERTA RIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdata\u001b[m\u001b[m/                       downscaling_analysis.ipynb\n",
      "downscaling.ipynb           \u001b[34mgraphs\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from sklearn.impute import KNNImputer\n",
    "from tqdm.notebook import tqdm\n",
    "import import_ipynb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from datetime import datetime, timedelta\n",
    "from downscaling import fit_bernoulli_gamma\n",
    "from scipy.stats import gamma\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertaRio():\n",
    "    \n",
    "    columns_v1 = {\n",
    "            \"string\": \"Dia         Hora      HBV   15 min   01 h   04 h   24 h   96 h\",\n",
    "            \"names\": [\"data\", \"hora\", \"HBV\", \"precipitation\", \"h01\", \"04h\", \"24h\", \"96h\"],\n",
    "        }\n",
    "    columns_v2 = {\n",
    "            \"string\": \"Dia         Hora      HBV   05 min   10 min   15 min   01 h   04 h   24 h   96 h\",\n",
    "            \"names\": [\n",
    "                \"data\",\n",
    "                \"hora\",\n",
    "                \"HBV\",\n",
    "                \"precipitation\",\n",
    "                \"10min\",\n",
    "                \"15min\",\n",
    "                \"h01\",\n",
    "                \"04h\",\n",
    "                \"24h\",\n",
    "                \"96h\",\n",
    "            ],\n",
    "        }\n",
    "    \n",
    "    def __init__(self,path):\n",
    "        self.data = pd.DataFrame(columns= [\"datetime\", \"precipitation\", \"h01\", \"station\"])\n",
    "        self.rain_gauge_path = Path(path)\n",
    "        self.stations = []\n",
    "        \n",
    "    def get_columns(self, filename):\n",
    "    \n",
    "        with open(filename) as f:\n",
    "            data = f.read().splitlines()\n",
    "        line = data[4].strip()\n",
    "        if not len(data) > 4:\n",
    "            return None\n",
    "        if line == self.columns_v1[\"string\"]:\n",
    "            \n",
    "            return self.columns_v1[\"names\"]\n",
    "        elif line == self.columns_v2[\"string\"]:\n",
    "            return self.columns_v2[\"names\"]\n",
    "        return None\n",
    "     \n",
    "    def process_station(self, station: str) -> pd.DataFrame:\n",
    "        \n",
    "        station_dfs = []\n",
    "        months = pd.date_range(pd.Timestamp(\"2011-01-01\"), pd.Timestamp(\"2024-10-01\"), freq=\"MS\")\n",
    "        for month in tqdm(months, desc=f\"Processing station {station}\", unit=\"month\", leave=False):\n",
    "            current_year = month.year\n",
    "            current_month = month.month\n",
    "            \n",
    "            try:\n",
    "                file_name = f\"{station}_{current_year:04d}{current_month:02d}_Plv.txt\"\n",
    "                file_path = self.rain_gauge_path/ file_name\n",
    "                if file_path.exists():\n",
    "                    # raise FileNotFoundError(f\"File {file_path} not found\")\n",
    "                    names = self.get_columns(file_path)\n",
    "                    if not names:\n",
    "                        print(f\"Columns cannot be inferred from file {file_path}.\")\n",
    "                    \n",
    "                    df = pd.read_csv(file_path , sep=r\"\\s+\", skiprows=5, header=None, names=names)\n",
    "                    rows_to_shift = df[df[\"HBV\"] != \"HBV\"].index\n",
    "                    df.loc[rows_to_shift, \"HBV\":] = df.loc[rows_to_shift, \"HBV\":].shift(1, axis=1)\n",
    "                    df = df[[\"data\", \"hora\", \"precipitation\", \"h01\"]]\n",
    "                \n",
    "                    df[\"datetime\"] = df[\"data\"] + \" \" + df[\"hora\"]\n",
    "                    df[\"datetime\"] = pd.to_datetime(\n",
    "                        df[\"datetime\"], dayfirst=True, errors=\"coerce\", format=\"%d/%m/%Y %H:%M:%S\"\n",
    "                    )\n",
    "                    df[\"precipitation\"] = pd.to_numeric(df[\"precipitation\"], errors=\"coerce\")\n",
    "                    df[\"h01\"] = pd.to_numeric(df[\"h01\"], errors=\"coerce\")\n",
    "                    df[\"station\"] = station\n",
    "                    df = df.drop(columns=[\"data\", \"hora\"])\n",
    "                    station_dfs.append(df)\n",
    "                else:\n",
    "                   print(f\"File {file_path} not found\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing station {station} at {current_year}-{current_month}: {e}\")\n",
    "                raise e\n",
    "        #assert len(station_dfs) == len(months)\n",
    "        df = pd.concat(station_dfs).sort_values(by=\"datetime\").reset_index(drop=True)\n",
    "        # df = self._impute_missing_values(df, AlertarioSchema.precipitation)\n",
    "        # df = self._impute_missing_values(df, AlertarioSchema.h01)\n",
    "        return df\n",
    "        \n",
    "    \n",
    "    def list_rain_gauge_stations(self) -> list[str]:\n",
    "        unique_names = set()\n",
    "        pattern = re.compile(r\"^(.*?)_\\d{6}_Plv\\.txt$\")\n",
    "        for file in self.rain_gauge_path.iterdir():\n",
    "            filename = file.name\n",
    "            match = pattern.match(filename)\n",
    "            if not match:\n",
    "                raise ValueError(f\"Filename {filename} does not match the pattern\")\n",
    "            unique_names.add(match.group(1))\n",
    "        return sorted(unique_names)\n",
    "        \n",
    "    def retrieve_all_stations_data(self):\n",
    "        self.stations = self.list_rain_gauge_stations()\n",
    "        for station in self.stations:\n",
    "            df = self.process_station(station)\n",
    "            self.data = pd.concat([self.data, df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitted_curve_and_histogram(data):\n",
    "    \n",
    "    stations = data['station'].unique()\n",
    "    df_filtered = data[data['precipitation'] > 0]\n",
    "    \n",
    "    for station in stations:\n",
    "        station_data = data[data['station'] == station]\n",
    "        \n",
    "        p, shape, loc, scale = fit_bernoulli_gamma(station_data['precipitation'])\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(df_filtered['precipitation'], density=True, label='Data', color='blue')\n",
    "\n",
    "        x = np.linspace(min(df_filtered['precipitation']), max(df_filtered['precipitation']), 50)\n",
    "        pdf_fitted = gamma.pdf(x, a=shape, loc=0.0, scale=scale)\n",
    "        plt.plot(x, pdf_fitted, 'r-', lw=2, label=f'Gamma Fit\\nshape={shape:.2f}, scale={scale:.2f}')\n",
    "\n",
    "        plt.xlabel(\"Precipitation\")\n",
    "        plt.ylabel(\"Fraction (Density)\")\n",
    "        plt.title(f'Scatter Plot with Fitted Curve - {station} station')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'histogram_fitted_gamma_curve/{station}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alertaRio = AlertaRio(\"data/alertario-from-source\")\n",
    "alertaRio.retrieve_all_stations_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fitted_curve_and_histogram(alertaRio.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
